# loader-engima
This repo will include loader components for both offline and online workloads.
The offline will sort based. We will generate a radnom file and ask a server component (using PHP) to sort it. 
The random file will be based on the baseline we agree on. e.g.,  

dd if=/dev/urandom of=1.log bs=5M count=2

Please note that the size of bs is determined by the VALUE the system needs to yield for the USER. i.e. if we anticipate a large files than bs will be bigger. 

The server will load the generated file 1.log and sort it. 

Our loader system will deploy the files across the compute system and log the processsing time.

Assuming we run Apache2 with Documentroot at /var/www/html, we are going to copy the load.php to /var/www/html

sudo cp load.php /var/www/html/

sudo cp 1.log /var/www/html/


The load will be generated by a simple script e.g. 

while (sleep 5)

do

curl $theipoftheserver/load.php
  
done

While we run it for couple of minutes we will observe ONE server only for general performance by executing on the SERVER:

tail -f /var/log/apache2/error.log

see if the test is valid and no otstanding errors are generated e.g., lack of memory.

Then execute the vmstat command on the SERVER and observe the reosurce utilization i.e. memory, swap, io, cpu etc. 

Once the server is in optimal utilization i.e. 60-70% utilization of the resources than we strart to measure the results.

Again, the results refers to VALUE we got from the system. The VALUE refers to the system utility i.e. user request per second.

The requests are logged in the apache access log under (per /etc/apache2/apache2.conf)

/var/log/apache2/access.log

Using the access log we measure the request per seconds or minutes.

